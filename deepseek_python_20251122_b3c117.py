#!/usr/bin/env python3
"""
Arabic LLM Stress Test Suite - Main Evaluator
Ø§Ù„Ù…Ù‚ÙŠÙ‘Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ø¬Ù‡Ø§Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
"""

import json
import asyncio
import argparse
from typing import Dict, List, Any
from pathlib import Path

from test_runner import TestRunner
from results_analyzer import ResultsAnalyzer
from utils.data_loader import DataLoader
from utils.report_generator import ReportGenerator

class StressTestEvaluator:
    def __init__(self, model_api=None):
        self.model_api = model_api
        self.test_runner = TestRunner(model_api)
        self.analyzer = ResultsAnalyzer()
        self.reporter = ReportGenerator()
        
    async def evaluate_model(self, model_name: str, test_categories: List[str] = None):
        """ØªÙ‚ÙŠÙŠÙ… Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ ÙØ¦Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©"""
        
        if test_categories is None:
            test_categories = ['cognitive', 'linguistic', 'cultural', 'reasoning']
        
        print(f"ğŸ” Ø¨Ø¯Ø¡ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {model_name}")
        print(f"ğŸ“‚ ÙØ¦Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {', '.join(test_categories)}")
        
        results = {}
        
        for category in test_categories:
            print(f"\nğŸ“ Ø¬Ø§Ø±ÙŠ Ø§Ø®ØªØ¨Ø§Ø± ÙØ¦Ø©: {category}")
            category_results = await self.test_runner.run_category_tests(category)
            results[category] = category_results
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
            self._print_category_summary(category, category_results)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        analysis = self.analyzer.analyze_results(results)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        report = self.reporter.generate_report(model_name, results, analysis)
        
        return report
    
    def _print_category_summary(self, category: str, results: Dict):
        """Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ù„ÙØ¦Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
        total_tests = len(results)
        passed_tests = sum(1 for r in results.values() if r.get('passed', False))
        
        print(f"   âœ… Ù†Ø¬Ø­: {passed_tests}/{total_tests}")
        print(f"   ğŸ“Š Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­: {(passed_tests/total_tests)*100:.1f}%")

async def main():
    parser = argparse.ArgumentParser(description='Arabic LLM Stress Test Suite')
    parser.add_argument('--model', type=str, required=True, help='Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªÙ‚ÙŠÙŠÙ…Ù‡')
    parser.add_argument('--categories', nargs='+', help='ÙØ¦Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±')
    parser.add_argument('--output', type=str, default='results', help='Ù…Ø¬Ù„Ø¯ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬')
    
    args = parser.parse_args()
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù‚ÙŠÙ‘Ù…
    evaluator = StressTestEvaluator()
    
    # Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
    report = await evaluator.evaluate_model(args.model, args.categories)
    
    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    output_file = Path(args.output) / f"{args.model}_report.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ¯ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ: {output_file}")

if __name__ == "__main__":
    asyncio.run(main())