# Arabic LLM Stress-Test Suite (ALSTS)
**Comprehensive Benchmarking for Arabic NLP Performance in Large Language Models (LLMs)**  
**ููุธููุฉ ุดุงููุฉ ูุงุฎุชุจุงุฑ ูุฅุฌูุงุฏ ููุงุฐุฌ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูู ุงููุบุฉ ุงูุนุฑุจูุฉ**

---

## ๐ Overview | ูุธุฑุฉ ุนุงูุฉ

ุชูุงุฌู ุงูููุงุฐุฌ ุงููุบููุฉ ุงููุจุฑู (LLMs) ุตุนูุจุงุช ุญููููุฉ ุนูุฏ ุงูุชุนุงูู ูุน ุงููุบุฉ ุงูุนุฑุจูุฉุ ุฎุงุตุฉู ูู:
- ุชุนุฏุฏ ุงูููุฌุงุช  
- ุงุฎุชูุงู ุงูุณูุงูุงุช ุงูุซูุงููุฉ  
- ุงููุตุทูุญุงุช ุงูุชูููุฉ  
- ุงูุงุณุชุฏูุงู ูุชุนุฏุฏ ุงูุฎุทูุงุช  
- ุงูููุทู ูุงูุฑูุงุถูุงุช  
- ุงููุตูุต ุงูุทูููุฉ  

ููุฐููุ ุชู ุฅูุดุงุก **ALSTS** ูุฃูู ูุดุฑูุน ููุชูุญ ุงููุตุฏุฑ ููุฏูู ุงุฎุชุจุงุฑุงุช ูุฃุฏุงุก ุงูููุงุฐุฌ ุจุงููุบุฉ ุงูุนุฑุจูุฉ ุนุจุฑ ุนุฏุฉ ูุญุงูุฑ.

---

# ๐ฆ Features | ุงููุฒุงูุง

## 1. Multi-Step Reasoning  
ุงุฎุชุจุงุฑุงุช ุนููุงููุฉ ุชุชุทูุจ 3โ5 ุฎุทูุงุช.

## 2. Computational Arabic  
ุงุฎุชุจุงุฑุงุช ุนููู ุงูุญุงุณูุจ ุจุงูุนุฑุจูุฉ ุงูุฃูุงุฏูููุฉ.

## 3. Cultural Sensitivity  
ุงุฎุชุจุงุฑุงุช ุงูุญุณุงุณูุฉ ููุณูุงู ุงูุนุฑุจู (ุฎููุฌู โ ูุตุฑู โ ุดุงููโฆ).

## 4. Logic & Math  
ุฃุณุฆูุฉ ููุทู ูุฑูุงุถูุงุช ููุดู ุงููููุณุฉ ุงูุญุณุงุจูุฉ.

## 5. Long-Text Handling  
ุงุฎุชุจุงุฑุงุช ูุนุงูุฌุฉ ุงููุตูุต ุงูุทูููุฉ.

---

# ๐ Example Tests | ุฃูุซูุฉ ุงุฎุชุจุงุฑุงุช

### 1. ููู ุงูููุฌุฉ ุงููุตุฑูุฉ
**Prompt:**  
"ูุง ูุนูู ุฌููุฉ (ุฅูุช ูุชูุถู ุชุนูููู ูููุง ูู ุจููุงุ) ูุงุดุฑุญ ุงูุณูุงู."

### 2. ุงููุตูุต ุงูุทูููุฉ
"ุงูุฑุฃ ุงููุต (800 ูููุฉ)ุ ุซู ูุฎุตูุ ุซู ุงุณุชุฎุฑุฌ ุงูุฃููุงุฑุ ุซู ุงูุชุฑุญ 3 ุฃุณุฆูุฉ ุชุญููููุฉ."

### 3. ุงูุฎูุงุฑุฒููุงุช
"ุงุดุฑุญ BFS ุจุงูุนุฑุจูุฉ ุงูุฃูุงุฏูููุฉุ ุซู ูุงุฑู ุจู DFS ูู ุญูุซ ุงูุฐุงูุฑุฉ."

### 4. ุงูุญุณุงุณูุฉ ุงูุซูุงููุฉ ุงูุฎููุฌูุฉ
"ูู ุนุจุงุฑุฉ (ุงููู ููุทุนู) ูุฒุญุฉ ุฃู ุฅุณุงุกุฉ ูู ุงูุซูุงูุฉ ุงููููุชูุฉุ ูุชู ุชูุณุชุฎุฏูุ"

---

# ๐ Repository Structure | ููููุฉ ุงููุดุฑูุน

Arabic-LLM-Stress-Test-Suite/
โ
โโโ prompts/
โ โโโ multi_step_reasoning.jsonl
โ โโโ computational_arabic.jsonl
โ โโโ cultural_sensitivity.jsonl
โ โโโ logic_and_math.jsonl
โ
โโโ evaluations/
โ โโโ gemini_results.md
โ โโโ grok_results.md
โ โโโ chatgpt_results.md
โ
โโโ notebooks/
โ โโโ evaluation_pipeline.ipynb
โ
โโโ requirements.txt


---

# โถ๏ธ How to Run | ุงูุชุดุบูู

## 1. Install Requirements
pip install -r requirements.txt

## 2. Run the Evaluation Notebook
ุงูุชุญ:
notebooks/evaluation_pipeline.ipynb

ูููู ุจู:
- ุชุญููู JSONL  
- ุชุดุบูู ุงููููุฐุฌ  
- ุงุณุชุฎุฑุงุฌ ุงููุชุงุฆุฌ  
- ุชุฎุฒูู ุงูุชูููู  

---

# ๐ Initial Results | ุงููุชุงุฆุฌ ุงูุฃูููุฉ

| Model | Accuracy | Reasoning | Culture | Math |
|-------|----------|-----------|--------|-------|
| GPT-4o-mini | 82% | ุฌูุฏ | ููุชุงุฒ | ุฌูุฏ |
| Gemini 1.5 Flash | 77% | ูุชูุณุท | ููุชุงุฒ | ูุชูุณุท |
| Grok 2 | 63% | ุถุนูู | ุถุนูู | ุถุนูู |
| Llama 3 8B | 55% | ุถุนูู | ูุชูุณุท | ุถุนูู |

---

# โจ Author | ุงููุคูู  
**Milad Aroumani โ M.Sc. Artificial Intelligence**  
Specialized in:  
- Arabic NLP  
- Prompt Engineering  
- AI Evaluation  
- LLM Training  

๐ง Email: mr.uefa@gmail.com  
๐ GitHub: https://github.com/Med-865
transformers
datasets
pandas
numpy
jupyter
accelerate
torch
multi_step_reasoning.jsonl
computational_arabic.jsonl
{"prompt": "ุงุดุฑุญ ููููู Big Oุ ุซู ุทุจููู ุนูู ุงูุจุญุซ ุงูุซูุงุฆูุ ุซู ุฃุนุท ูุซุงูุงู.", "difficulty": "hard"}
{"prompt": "ุญููู Merge Sortุ ุซู ูุถูุญ ููุงุฐุง ุชุญุชุงุฌ ูุณุงุญุฉ ุฅุถุงููุฉ.", "difficulty": "hard"}
{"prompt": "ุงุดุฑุญ ุงูุนูุงูุฉ ุจูู ุงูููุงุกุฉ ูุงูุฐุงูุฑุฉุ ุซู ุทุจูููุง ุนูู DFS ูBFS.", "difficulty": "hard"}
{"prompt": "ุงุดุฑุญ ุฎูุงุฑุฒููุฉ BFS ุจุงูุนุฑุจูุฉ ุงูุฃูุงุฏูููุฉ.", "category": "cs"}
{"prompt": "ูุงุฑู ุจูู Stack ูQueue ุจูุซุงู ุจุฑูุฌู.", "category": "cs"}
{"prompt": "ุญูู ุงูุชุนููุฏ ุงูุฒููู ูู QuickSort.", "category": "cs"}
{"prompt": "ูู ูููุฉ (ุซูู ุฏู) ูุฌุงููุฉ ุฃู ุฅูุงูุฉ ูู ุงูุซูุงูุฉ ุงููุตุฑูุฉุ", "category": "culture"}
{"prompt": "ูุง ูุนูู (ุนุณู ูุง ุดุฑ) ูู ุงูุซูุงูุฉ ุงููููุชูุฉุ", "category": "culture"}
{"prompt": "ูู ุนุจุงุฑุฉ (ุดู ุจุฏูุ) ุนุฏูุงููุฉ ูู ุงูุดุงูุ", "category": "culture"}
gemini_results.md
# Gemini Evaluation Results
Gemini 1.5 Flash tested on 20 prompts.

- Multi-step reasoning: ูุชูุณุท  
- Culture: ููุชุงุฒ  
- Math: ูุชูุณุท  
- Logic: ุฌูุฏ  
grok_results.md
# Grok Evaluation Results
Grok 2 tested on 20 prompts.

- Reasoning: ุถุนูู  
- Culture: ุถุนูู  
- Math: ุถุนูู ุฌุฏุงู  
chatgpt_results.md
# ChatGPT Evaluation Results
GPT-4o-mini tested on 20 prompts.

- Reasoning: ุฌูุฏ  
- Culture: ููุชุงุฒ  
- Math: ุฌูุฏ  


import json
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

model_name = "meta-llama/Llama-3-8B"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)

def run_prompt(prompt):
    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(**inputs, max_new_tokens=150)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

with open("../prompts/multi_step_reasoning.jsonl", "r", encoding="utf-8") as f:
    lines = f.readlines()

for l in lines:
    data = json.loads(l)
    print("PROMPT:", data["prompt"])
    print("RESPONSE:", run_prompt(data["prompt"]))
    print("-----")
